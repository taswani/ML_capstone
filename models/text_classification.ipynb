{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Sentiment Analysis notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_pipeline as dp\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running all the functions from the data pipeline to get us the results dataframe and the processed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Headlines</th>\n",
       "      <th>Average Mean</th>\n",
       "      <th>Differential</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>717.200012</td>\n",
       "      <td>719.369995</td>\n",
       "      <td>712.539978</td>\n",
       "      <td>715.619995</td>\n",
       "      <td>Amazon Inspire, a resource site where teachers...</td>\n",
       "      <td>938.977200</td>\n",
       "      <td>6.830017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-10-02</td>\n",
       "      <td>717.200012</td>\n",
       "      <td>719.369995</td>\n",
       "      <td>712.539978</td>\n",
       "      <td>715.619995</td>\n",
       "      <td>The e-commerce giant has big plans to use auto...</td>\n",
       "      <td>938.977200</td>\n",
       "      <td>6.830017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>831.239990</td>\n",
       "      <td>831.719971</td>\n",
       "      <td>815.429993</td>\n",
       "      <td>818.359985</td>\n",
       "      <td>The creator of “Mad Men” has signed on for an ...</td>\n",
       "      <td>938.977200</td>\n",
       "      <td>16.289978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>782.000000</td>\n",
       "      <td>789.489990</td>\n",
       "      <td>774.609985</td>\n",
       "      <td>776.320007</td>\n",
       "      <td>The company said to expect as much as $1.25 bi...</td>\n",
       "      <td>938.977200</td>\n",
       "      <td>14.880005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>745.000000</td>\n",
       "      <td>761.489990</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>759.359985</td>\n",
       "      <td>At an experimental store on the ground floor o...</td>\n",
       "      <td>938.977200</td>\n",
       "      <td>19.489990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-08-07</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>1964.400024</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>1962.459961</td>\n",
       "      <td>Here’s what you need to know at the end of the...</td>\n",
       "      <td>1947.702667</td>\n",
       "      <td>28.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-08-08</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>1964.400024</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>1962.459961</td>\n",
       "      <td>Both the gourmet grocer and the rarefied depar...</td>\n",
       "      <td>1948.954467</td>\n",
       "      <td>28.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>1964.400024</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>1962.459961</td>\n",
       "      <td>Amazon is trying, starting with a new Jim Gaff...</td>\n",
       "      <td>1950.220667</td>\n",
       "      <td>28.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-08-10</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>1964.400024</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>1962.459961</td>\n",
       "      <td>Julio Torres shares the stories of inanimate o...</td>\n",
       "      <td>1951.371967</td>\n",
       "      <td>28.400024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>1949.000000</td>\n",
       "      <td>1964.400024</td>\n",
       "      <td>1936.000000</td>\n",
       "      <td>1962.459961</td>\n",
       "      <td>The couple met in 2011 while playing in Washin...</td>\n",
       "      <td>1952.555867</td>\n",
       "      <td>28.400024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close  \\\n",
       "Date                                                             \n",
       "2016-06-30   717.200012   719.369995   712.539978   715.619995   \n",
       "2016-10-02   717.200012   719.369995   712.539978   715.619995   \n",
       "2016-10-27   831.239990   831.719971   815.429993   818.359985   \n",
       "2016-10-28   782.000000   789.489990   774.609985   776.320007   \n",
       "2016-12-05   745.000000   761.489990   742.000000   759.359985   \n",
       "...                 ...          ...          ...          ...   \n",
       "2019-08-07  1949.000000  1964.400024  1936.000000  1962.459961   \n",
       "2019-08-08  1949.000000  1964.400024  1936.000000  1962.459961   \n",
       "2019-08-09  1949.000000  1964.400024  1936.000000  1962.459961   \n",
       "2019-08-10  1949.000000  1964.400024  1936.000000  1962.459961   \n",
       "2019-08-11  1949.000000  1964.400024  1936.000000  1962.459961   \n",
       "\n",
       "                                                    Headlines  Average Mean  \\\n",
       "Date                                                                          \n",
       "2016-06-30  Amazon Inspire, a resource site where teachers...    938.977200   \n",
       "2016-10-02  The e-commerce giant has big plans to use auto...    938.977200   \n",
       "2016-10-27  The creator of “Mad Men” has signed on for an ...    938.977200   \n",
       "2016-10-28  The company said to expect as much as $1.25 bi...    938.977200   \n",
       "2016-12-05  At an experimental store on the ground floor o...    938.977200   \n",
       "...                                                       ...           ...   \n",
       "2019-08-07  Here’s what you need to know at the end of the...   1947.702667   \n",
       "2019-08-08  Both the gourmet grocer and the rarefied depar...   1948.954467   \n",
       "2019-08-09  Amazon is trying, starting with a new Jim Gaff...   1950.220667   \n",
       "2019-08-10  Julio Torres shares the stories of inanimate o...   1951.371967   \n",
       "2019-08-11  The couple met in 2011 while playing in Washin...   1952.555867   \n",
       "\n",
       "            Differential  \n",
       "Date                      \n",
       "2016-06-30      6.830017  \n",
       "2016-10-02      6.830017  \n",
       "2016-10-27     16.289978  \n",
       "2016-10-28     14.880005  \n",
       "2016-12-05     19.489990  \n",
       "...                  ...  \n",
       "2019-08-07     28.400024  \n",
       "2019-08-08     28.400024  \n",
       "2019-08-09     28.400024  \n",
       "2019-08-10     28.400024  \n",
       "2019-08-11     28.400024  \n",
       "\n",
       "[455 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = dp.prepare_data(dp.price_csv, dp.headline_csv)\n",
    "processed_features = dp.vectorization(result_df)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look to use pre-trained model, aggregrate the predictions and append to result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(result_df, processed_features):\n",
    "    # List for taking in the sentiments associated with the processed features\n",
    "    sentiments = []\n",
    "    polarity = []\n",
    "    # Using a pre-trained model to analyze sentiment for each headline\n",
    "    for feature in processed_features:\n",
    "        sentence = TextBlob(feature)\n",
    "        polarity.append(sentence.sentiment.polarity)\n",
    "        if sentence.sentiment.polarity > 0:\n",
    "            sentiments.append(1)\n",
    "        else:\n",
    "            sentiments.append(0)\n",
    "    # Adding a new column in the dataframe and returning it\n",
    "    result_df['Sentiment'] = sentiments\n",
    "    result_df['Polarity'] = polarity\n",
    "    # pushing df to a csv\n",
    "    result_df.to_csv(\"final_amazon.csv\")\n",
    "    return result_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
